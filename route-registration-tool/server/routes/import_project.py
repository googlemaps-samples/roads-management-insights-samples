# Copyright 2026 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import json
import io
import zipfile
import logging
import uuid
from fastapi import APIRouter, UploadFile, File, Form, HTTPException
from sqlalchemy import text
from sqlalchemy.exc import DatabaseError, IntegrityError, OperationalError
from server.utils.create_engine import engine
from server.utils.verify_project_details import verify_project_details
from server.utils.feature_flags import ENABLE_MULTITENANT

router = APIRouter()
logger = logging.getLogger("project_import")


async def import_project_from_zip(zip_bytes: bytes):
    """
    Import project + routes from a .zip file generated by the export function.
    """

    try:
        with zipfile.ZipFile(io.BytesIO(zip_bytes)) as zf:
            json_files = [name for name in zf.namelist() if name.endswith(".json")]

            if not json_files:
                raise ValueError("No JSON file found inside ZIP.")

            json_bytes = zf.read(json_files[0])
            data = json.loads(json_bytes)

    except Exception as e:
        logger.error(f"Failed to read import ZIP: {str(e)}")
        raise ValueError("Invalid ZIP structure or corrupted file.") from e

    if "project" not in data or "routes" not in data:
        raise ValueError("Invalid JSON export format.")

    json_project = data["project"]
    project_id = json_project.get("id")
    # Preserve project_uuid from export so the same project identity is kept on import
    project_uuid_val = json_project.get("project_uuid")
    if not project_uuid_val:
        project_uuid_val = str(uuid.uuid4())
    project_name = json_project.get("project_name")
    google_cloud_project_id = json_project.get("google_cloud_project_id")
    google_cloud_project_number = json_project.get("google_cloud_project_number")
    subscription_id = json_project.get("subscription_id")
    dataset_name = json_project.get("dataset_name") or "historical_roads_data"
    viewstate = json_project.get("viewstate")
    jurisdiction_boundary_geojson = json_project.get("jurisdiction_boundary_geojson")
    map_snapshot = json_project.get("map_snapshot")

    routes_list = data["routes"]

    if jurisdiction_boundary_geojson is None or viewstate is None:
        raise ValueError("JSON missing required project fields (jurisdiction or viewstate).")

    if not google_cloud_project_id:
        raise ValueError("Google Cloud Project ID is required but missing from the import file.")

    try:
        verifying_project = await verify_project_details(google_cloud_project_id)
        
        # verify_project_details returns a dict with project_number and project_id on success
        if not verifying_project or "project_id" not in verifying_project:
            raise ValueError("Failed to verify Google Cloud Project. Please check your project ID and permissions.")
            
    except HTTPException as e:
        # Convert HTTPException from verify_project_details to ValueError with user-friendly message
        if e.status_code == 403:
            error_detail = e.detail
            raise ValueError("You don't have access to this project. Please check your Google Cloud Project permissions.")
        elif e.status_code == 404:
            raise ValueError(
                f"Google Cloud Project '{google_cloud_project_id}' not found. "
                f"Please verify the project ID is correct."
            )
        else:
            raise ValueError("Failed to verify Google Cloud Project. Please check your Google Cloud Project ID and permissions.")
    except Exception as e:
        # Catch any other unexpected errors from verify_project_details
        logger.error(f"Unexpected error verifying project {google_cloud_project_id}: {str(e)}")
        raise ValueError(
            f"Failed to verify Google Cloud Project '{google_cloud_project_id}'. "
            f"Please check your authentication and project permissions."
        )

    try:
        # Pre-insert check: when single-tenant, reject if GCP project ID is already in use (no UNIQUE constraint in DB).
        if not ENABLE_MULTITENANT and google_cloud_project_id:
            with engine.connect() as _conn:
                existing_row = _conn.execute(
                    text(
                        "SELECT project_name FROM projects WHERE google_cloud_project_id = :gcp AND deleted_at IS NULL"
                    ),
                    {"gcp": google_cloud_project_id},
                ).fetchone()
                if existing_row:
                    raise ValueError(
                        f"You're trying to upload a project with a Google Cloud Project ID that's already in use by '{existing_row[0]}'."
                    )
        with engine.begin() as conn:
            existing_project = conn.execute(
                text("SELECT 1 FROM projects WHERE id = :id"),
                {"id": project_id},
            ).fetchone()
            if existing_project:
                project_id = conn.execute(
                    text("""
                        INSERT INTO projects (project_uuid, project_name, jurisdiction_boundary_geojson, google_cloud_project_id,
                            google_cloud_project_number, subscription_id, dataset_name, viewstate, map_snapshot)
                        VALUES (:project_uuid, :project_name, :jurisdiction_boundary_geojson, :google_cloud_project_id,
                            :google_cloud_project_number, :subscription_id, :dataset_name, :viewstate, :map_snapshot)
                        RETURNING id;
                    """),
                    {
                        "project_uuid": project_uuid_val,
                        "project_name": project_name,
                        "jurisdiction_boundary_geojson": jurisdiction_boundary_geojson,
                        "google_cloud_project_id": google_cloud_project_id,
                        "google_cloud_project_number": google_cloud_project_number,
                        "subscription_id": subscription_id,
                        "dataset_name": dataset_name,
                        "viewstate": viewstate,
                        "map_snapshot": map_snapshot,
                    },
                ).scalar()
            else:
                conn.execute(text(""" INSERT INTO projects (id, project_uuid, project_name, jurisdiction_boundary_geojson, google_cloud_project_id, google_cloud_project_number, subscription_id, dataset_name, viewstate, map_snapshot) VALUES (:id, :project_uuid, :project_name, :jurisdiction_boundary_geojson, :google_cloud_project_id, :google_cloud_project_number, :subscription_id, :dataset_name, :viewstate, :map_snapshot) """), {
                    "id": project_id,
                    "project_uuid": project_uuid_val,
                    "project_name": project_name,
                    "jurisdiction_boundary_geojson": jurisdiction_boundary_geojson,
                    "google_cloud_project_id": google_cloud_project_id,
                    "google_cloud_project_number": google_cloud_project_number,
                    "subscription_id": subscription_id,
                    "dataset_name": dataset_name,
                    "viewstate": viewstate,
                    "map_snapshot": map_snapshot,
                })


            logger.info(f"Project imported with ID: {project_id}")

            inserted = 0
            skipped = 0
            uuid_conflicts = 0

            for route in routes_list:
                route_uuid = route.get("uuid")
                if not route_uuid:
                    skipped += 1
                    continue

                # Check if UUID exists
                exists = conn.execute(
                    text("SELECT 1 FROM routes WHERE uuid = :uuid"),
                    {"uuid": route_uuid},
                ).fetchone()

                # If UUID exists, generate a new one and update the route
                if exists:
                    new_uuid = str(uuid.uuid4())
                    route["uuid"] = new_uuid
                    route["sync_status"] = "unsynced"
                    route["synced_at"] = None
                    route["routes_status"] = "UNSYNCED"
                    uuid_conflicts += 1

                # Ensure the new project ID and project UUID are used
                route["project_id"] = project_id
                route["project_uuid"] = project_uuid_val

                # Build dynamic SQL for route insert
                cols = ", ".join(route.keys())
                vals = ", ".join([f":{k}" for k in route.keys()])

                conn.execute(
                    text(f"INSERT INTO routes ({cols}) VALUES ({vals})"),
                    route,
                )

                inserted += 1
    except IntegrityError as e:
        error_msg = str(e.orig) if e.orig else str(e)
        logger.error(f"Database integrity error during project import: {error_msg}")
        if "UNIQUE constraint failed" in error_msg:
            if not ENABLE_MULTITENANT and google_cloud_project_id:
                # Single-tenant: friendly message when GCP ID already in use
                with engine.begin() as conn:
                    row = conn.execute(
                        text(
                            "SELECT project_name FROM projects WHERE google_cloud_project_id = :value AND deleted_at IS NULL"
                        ),
                        {"value": google_cloud_project_id},
                    ).fetchone()
                if row:
                    raise ValueError(
                        f"You're trying to upload a project with a Google Cloud Project ID that's already in use by '{row[0]}'."
                    )
            raise ValueError(
                "A record with this value already exists. "
                "Check that project name and other unique fields are not duplicated."
            )
        raise ValueError(f"Database integrity error: {error_msg}")
    except OperationalError as e:
        error_msg = str(e.orig) if e.orig else str(e)
        logger.error(f"Database operational error during project import: {error_msg}")
        raise ValueError(f"Database connection error. Please try again later.")
    except DatabaseError as e:
        error_msg = str(e.orig) if e.orig else str(e)
        logger.error(f"Database error during project import: {error_msg}")
        raise ValueError(f"Database error occurred. Please check your data and try again.")

    return {
        "new_project_id": project_id,
        "routes_inserted": inserted,
        "routes_skipped_no_uuid": skipped,
        "routes_uuid_conflicts_resolved": uuid_conflicts,
    }

@router.post("/import_project")
async def import_project(file: UploadFile = File(...)):
    """
    Import project + routes from a .zip file generated by the export function.
    """

    filename = file.filename
    if not filename or not filename.endswith(".zip"):
        raise HTTPException(status_code=400, detail="File must be a .zip export.")

    try:
        zip_bytes = await file.read()

        result = await import_project_from_zip(zip_bytes)

    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"Unexpected error importing project: {str(e)}")
        raise HTTPException(status_code=500, detail="Internal server error")

    return {
        "status": "success",
        **result,
    }
